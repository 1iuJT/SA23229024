---
title: "Introduction to SA23229024"
author: "Liu jingtao"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to SA23229024}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

__SA23229024__ is a generic R package used for "Statistical computing" courses. Contains two R functions, That is, _Gibbs_plot_(performs Gibbs sampling and creates plots for the sampling chain.) and _simulate_p_values_(Simulate P-Values and Compare Correction Methods). In addition, contains two Cpp functions, That is, _gibbs_sampling_iter_(performs a single iteration of Gibbs sampling for bivariate normal distribution) and _Gibbs_sampling_cpp_(A Gibbs sampler using Rcpp) are used to accelerate the execution speed and statistical accuracy of _Gibbs_plot_.

### Background of simulate_p_values.R 

In statistical significance tests, researchers often test multiple hypotheses simultaneously. As the number of hypotheses tested increases, the risk of at least one Type I error (that is, a false rejection of a true null hypothesis) increases. To control for this error rate, researchers use multiple comparison correction methods. Bonferroni correction and Benjamini-Hochberg (B-H) correction are two widely used robust methods. The Bonferroni correction assigns the significance level to all hypothesis tests, while the B-H correction controls for the proportion of all findings claimed to be significant that are incorrectly judged to be significant, known as the false-discovery rate (FDR).

This R function _simulate_p_values_ is designed to evaluate the effectiveness of rejecting the null hypothesis under different multiple comparison correction methods, and to provide an average indicator of statistical performance evaluation. This function can help to understand the combined effect of correction methods on identifying true positive discovery effects under different hypothesis distributions.

### Guidelines of simulate_p_values.R 

The source R code for _simulate_p_values_ is as follows:
```{r,eval=FALSE}
simulate_p_values <- function(m = 1000, M = 1000, pvalue_distribution_null = runif,
                              dist_params_null = list(0,1),
                              pvalue_distribution_alt = rbeta,
                              dist_params_alt = list(0.1,1),
                              alpha = 0.1) {

  # Initialize matrices to store error rates and power
  tdr <- fwer <- tpr <- fdr <- f1 <- matrix(NA, nrow = 2, ncol = M) 

  for (j in 1:M) {

    # Generate p-values: (1-alpha)*m from null and alpha*m from alternative
    pvalue <- c(do.call(pvalue_distribution_null, c(list(m - m / 20), dist_params_null)),
                do.call(pvalue_distribution_alt, c(list(m / 20), dist_params_alt)))

    # Bonferroni method
    pvalue.Bonf <- p.adjust(pvalue, method = "bonferroni") # Adjust p-values using Bonferroni correction
    reject.Bonf <- pvalue.Bonf < alpha # Determine which hypotheses to reject
    # Calculate true discovery rate (TDR), family-wise error rate (FWER), false discovery rate (FDR), true positive rate (TPR), and F1 score for Bonferroni method
    tdr[1,j] <-  sum(reject.Bonf[(m - m / 20 + 1):m]) / max(sum(reject.Bonf), 1)
    fwer[1, j] <- any(reject.Bonf[1:(m - m / 20)])
    fdr[1, j] <- sum(reject.Bonf[1:(m - m / 20)]) / max(sum(reject.Bonf), 1)
    tpr[1,j] <- sum(reject.Bonf[(m - m / 20 + 1):m]) / (m / 20)
    f1[1,j] <- 2*(tdr[1,j]*tpr[1,j])/(tdr[1,j]+tpr[1,j])
    
    # BH (Benjamini-Hochberg) method
    pvalue.BH <- p.adjust(pvalue, method = "BH") # Adjust p-values using Benjamini-Hochberg method
    reject.BH <- pvalue.BH < alpha # Determine which hypotheses to reject
    # Calculate TDR, FWER, FDR, TPR, and F1 score for BH method
    tdr[2,j] <- sum(reject.BH[(m - m / 20 + 1):m]) / max(sum(reject.BH), 1)
    fwer[2, j] <- any(reject.BH[1:(m - m / 20)])
    fdr[2, j] <- sum(reject.BH[1:(m - m / 20)]) / max(sum(reject.BH), 1)
    tpr[2,j] <- sum(reject.BH[(m - m / 20 + 1):m]) / (m / 20)
    f1[2,j] <- 2*(tdr[2,j]*tpr[2,j])/(tdr[2,j]+tpr[2,j])
  }

  # Return the mean of each metric across all simulations for both methods
  result <- matrix(c(rowMeans(tdr, na.rm = TRUE), rowMeans(tpr, na.rm = TRUE), rowMeans(fdr, na.rm = TRUE),
                   rowMeans(fwer, na.rm = TRUE), rowMeans(f1, na.rm = TRUE)),nrow = 2)
  colnames(result) <- c("TDR", "TPR", "FDR", "FWER", "F1_score")
  rownames(result) <- c("Bonf", "BH")
  
  return(result)
}
```

The R code for use _simulate_p_values_  is as follows.
```{r,eval=FALSE}
set.seed(2023) # for reproducibilit
simulate_p_values(m = 1000, M = 1000, pvalue_distribution_null = runif,
                        dist_params_null = list(0, 1),
                        pvalue_distribution_alt = rbeta,
                        dist_params_alt = list(0.1, 1),
                        alpha = 0.1)
```

When using the _simulate_p_values_ function, users can select different null hypothesis and alternative hypothesis distributions (such as rbeta  rf rt rexp rnorm.) according to the specific context of their research.The R code for example is as follows.
```{r,eval=FALSE}
set.seed(2023) # for reproducibilit
simulate_p_values(m = 1000, M = 1000, pvalue_distribution_null = runif,
                        dist_params_null = list(0,1),
                        pvalue_distribution_alt = rt,
                        dist_params_alt = list(10),
                        alpha = 0.05)
```

### Background of Gibbs_plot.R and Gibbs_sampling.cpp

Gibbs sampling is a Markov chain Monte Carlo (MCMC) method often used to generate random samples with complex distributions that are difficult to sample directly. This method is widely used in Bayesian statistics to obtain samples from a joint posterior distribution. In the context of a multivariate normal distribution, Gibbs sampling is particularly useful because it allows researchers to gradually build a sample of the entire multivariate normal distribution through the conditional normal distribution.

_Gibbs_plot_ function implements Gibbs sampling to generate a bivariate normal chain with adjustable mean, unit standard deviation, and correlation coefficient. Then it fits a simple linear regression model and performs normality and variance homogeneity tests for the residuals. These steps are crucial for verifying the fit and prediction accuracy of the model.

The _Gibbs_sampling_ function takes advantage of the performance benefits of C++ and the Rcpp package by performing Gibbs sampling in R to generate a bivariate normal chain (Xt, Yt). This function implements Gibbs sampling of a bivariate normal distribution, generated by conditionally distributed sequential sampling (Xt, Yt). Compared to the Gibbs_plot function implemented in pure R, the _Gibbs_sampling__cpp_ function greatly improves the operation efficiency by migrating the calculation and sampling process to C++. This feature is particularly useful for large-scale simulation studies, where a large number of samples may need to be generated to ensure adequate statistical accura

### Guidelines of simulate_p_values.R 

The source R code for _Gibbs_plot_ is as follows:
```{r,eval=FALSE}
Gibbs_plot <- function(N, burnin, sigma, mu, set_seed = 2012) {

  # Same function body as previously provided
  if (!is.null(set_seed)) {
    set.seed(set_seed)
  }
  cpp_path <- system.file("src", "Gibbs_sampling.cpp", package = "SA23229024")

  # 确保文件存在
  if (!file.exists(cpp_path)) {
    stop("Cannot find Gibbs_sampling.cpp in the src directory of the package")
  }
  # Source the C++ function
  sourceCpp(cpp_path)

  # 进行Gibbs采样
  chain <- Gibbs_sampling_cpp(N, burnin, sigma, mu)

  chain_df <- data.frame(x=chain[,1], y=chain[,2])
  # 绘图
  p <- ggplot(chain_df, aes(x=chain_df$x, y=chain_df$y)) +
    geom_point(alpha=0.3) +
    theme_bw() +
    labs(x="Xt", y="Yt")
  print(p)

  # 线性回归拟合
  fit <- lm(chain_df$y ~ chain_df$x, data=chain_df)

  # 正态性检验
  resids <- residuals(fit)
  shapiro_test <- shapiro.test(resids)

  # 残差的检查
  resids <- residuals(fit)

  # 残差和方差定性检验
  plot(fit, which=1)  # Residuals vs Fitted
  plot(fit, which=3)  # Scale-Location (检查异方差性)

  # 返回线性模型拟合结果和Shapiro-Wilk测试结果
  return(list(fit = fit, shapiro = shapiro_test))
}

```
The source Cpp code for _Gibbs_plot_ is as follows:
```{cpp,eval=FALSE}
NumericMatrix Gibbs_sampling_cpp(int N, int burnin, NumericMatrix sigma, NumericVector mu) {
   NumericMatrix chain(N, 2);
   chain(0, 0) = R::rnorm(mu(0), sigma(0, 0));
   chain(0, 1) = R::rnorm(mu(1), sigma(1, 1));

   // Perform the Gibbs sampling
   for (int i = 1; i < N + burnin; i++) {
     // For actual sample use the last row of the chain, for burn-in use the last sampled values
     NumericVector last_sample = i < burnin ? NumericVector::create(chain(i - 1, 0), chain(i - 1, 1)) : chain(i - burnin, _);
     NumericVector sample = gibbs_sampling_iter(last_sample, sigma, mu);
     if (i >= burnin) {
       chain(i - burnin, _) = sample;
     }
   }

  return chain;
}
```

The source Cpp code for _Gibbs_sampling_cpp_ is as follows:
```{cpp,eval=FALSE}
NumericVector gibbs_sampling_iter(const NumericVector& last_sample, const NumericMatrix& sigma, const NumericVector& mu) {
  NumericVector sample(2);
  double sigma11 = sigma(0, 0);
  double sigma12 = sigma(0, 1);
  double sigma22 = sigma(1, 1);
  double mu1 = mu(0);
  double mu2 = mu(1);

  sample(0) = R::rnorm(mu1 + sigma12 * (last_sample(1) - mu2) / sigma22,
         std::sqrt(sigma11 - sigma12 * sigma12 / sigma22));
  sample(1) = R::rnorm(mu2 + sigma12 * (sample(0) - mu1) / sigma11,
         std::sqrt(sigma22 - sigma12 * sigma12 / sigma11));
  return sample;
}
```

$Parameter setting: \quad$ The user needs to set the number of iterations N and burnin. The burn-in period refers to the initial number of samples generated and discarded prior to actual analysis so that the chain can reach its smooth distribution, ensuring that subsequent sampling is not affected by initial conditions.

$Covariance matrix and mean vector: \quad$  The sigma parameter is set to the covariance matrix of the target bivariate normal distribution. In this case, the diagonal element is 1 (because the standard deviation is 1) and the non-diagonal element is 0.9 (because the correlation coefficient is 0.9). The mean vector mu is set to c(0,0).

The R code for use _Gibbs_plot_  is as follows.
```{r,eval=FALSE}
# Set random number seeds to ensure reproducible results
set.seed(2023)  
results <- Gibbs_plot(N = 2000, burnin = 500, sigma = matrix(c(1,0.9,0.9,1),
                                                             nrow=2), mu = c(0,0))
# View summary information for linear models
summary(results$fit)

 # View the results of the Shapiro-Wilk normality test
results$shapiro

```

When using the _Gibbs_plot_ function, users can select different mean, unit standard deviation, correlation coefficient, etc., according to the specific context of their research.The R code for example is as follows.
```{r,eval=FALSE}
# Set random number seeds to ensure reproducible results
set.seed(2023)  
results <- Gibbs_plot(N = 5000, burnin = 1000, sigma = matrix(c(1, 0.7, 0.7, 1),
                                                               nrow=2), mu = c(-1, 1))
# View summary information for linear models
summary(results$fit)

 # View the results of the Shapiro-Wilk normality test
results$shapiro
```
